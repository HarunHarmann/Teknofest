{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcc/K6PZzRGdnx1lNsPlDl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarunHarmann/Teknofest/blob/main/'Pozisyon%20Kestirimi'/SIFT_Pozisyon_Kestirimi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQPLu_yjSlfv"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from decimal import Decimal\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "7nmNhSMmSmjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth = pd.read_csv(\"GT_Translations.csv\")\n",
        "ground_truth"
      ],
      "metadata": {
        "id": "TftdiqX8Sn52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Görüntülerin ve kalibrasyon parametrelerinin değişkene atanması"
      ],
      "metadata": {
        "id": "5S68XFlFSrvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# img_path = \"/content/drive/MyDrive/Teknofest/Datasets/Pozisyon_Kestirimi/Oturum1_Part2\"\n",
        "img_path = \"/content/drive/MyDrive/Teknofest/Datasets/frame/\"\n",
        "file_names = sorted([file_name for file_name in os.listdir(img_path) if file_name.endswith(('.jpg', '.png'))])\n",
        "\n",
        "# Görüntü dosya yollarını bir listeye ekleyin\n",
        "image_files = [os.path.join(img_path, file_name) for file_name in file_names]\n",
        "\n",
        "# Görüntüleri bir diziye ekleyin\n",
        "images = [cv2.imread(image) for image in image_files]\n",
        "\n",
        "print(len(images))"
      ],
      "metadata": {
        "id": "PB0JkssBSssI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intrinsicMatrix = None\n",
        "focalLength = None\n",
        "principalPoint = None\n",
        "radialDistortion = (-0.0091, 0.0666)\n",
        "tangentialDistortion = (0,0)\n",
        "imageSize = None\n",
        "rotationMatrices = None\n",
        "translationVectors = None\n",
        "meanReprojectionError = None\n",
        "reprojectionErrors = None\n",
        "reprojectedPoints = None\n",
        "numPatterns = None\n",
        "worldPoints = None\n",
        "worldUnits = None\n",
        "estimateSkew = None\n",
        "numRadialDistortionCoefficients = None\n",
        "estimateTangentialDistortion = None\n",
        "\n",
        "# /content/drive/MyDrive/Teknofest/Datasets/Pozisyon_Kestirimi/kalibrasyon.txt\n",
        "with open('kalibrasyon.txt', 'r') as file:\n",
        "    file_contents = file.readlines()\n",
        "\n",
        "\n",
        "# Değişkenlere atama\n",
        "for line in file_contents:\n",
        "    if 'IntrinsicMatrix' in line:\n",
        "      intrinsicMatrix = [[0.0 for _ in range(int(line.split(':')[1][4]))] for _ in range(int(line.split(':')[1][2]))]\n",
        "      print(intrinsicMatrix)\n",
        "    elif 'FocalLength' in line:\n",
        "      focalLength = (float(line.split(':')[1].split()[0][1:]),float(line.split(':')[1].split()[1][:-1]))\n",
        "      print(focalLength)\n",
        "    elif 'PrincipalPoint' in line:\n",
        "      principalPoint = (float(line.split(':')[1].split()[0][1:]),float(line.split(':')[1].split()[1][:-1]))\n",
        "      print(principalPoint)\n",
        "    # elif 'RadialDistortion' in line:\n",
        "    #   print(float(line.split(':')[1].split()[1][:-1]))\n",
        "    #   radialDistortion = (float(line.split(':')[1].split()[0][1:]),float(line.split(':')[1].split(\" \")[1][:-1]))\n",
        "    #   print(radialDistortion)\n",
        "    # elif 'TangentialDistortion' in line:\n",
        "    #   tangentialDistortion = (float(line.split(':')[1].split()[0][1:]),float(line.split(':')[1].split()[1][:-1]))\n",
        "    #   print(tangentialDistortion)\n",
        "    elif 'ImageSize' in line:\n",
        "      imageSize = (int(line.split(':')[1].split()[0][1:]),int(line.split(':')[1].split()[1][:-1]))\n",
        "      print(imageSize)\n",
        "    elif 'RotationMatrices' in line:\n",
        "      part = line.split(':')[1].split(\" \")[1].split(\"x\")\n",
        "      rotationMatrices = [[ [0.0 for col in range(int(part[2]))] for col in range(int(part[1]))] for row in range(int(part[0][1:]))]\n",
        "      print(rotationMatrices)\n",
        "    elif 'TranslationVectors' in line:\n",
        "      part = line.split(':')[1].split(\" \")[1].split(\"x\")\n",
        "      translationVectors = [[0.0]*int(part[1])]*int(part[0][1:])\n",
        "      print(translationVectors)\n",
        "    elif 'MeanReprojectionError' in line:\n",
        "      meanReprojectionError = float(line.split(':')[1])\n",
        "      print(meanReprojectionError)\n",
        "    elif 'ReprojectionErrors' in line:\n",
        "      part = line.split(':')[1].split(\" \")[1].split(\"x\")\n",
        "      reprojectionErrors = [[ [0.0 for col in range(int(part[2]))] for col in range(int(part[1]))] for row in range(int(part[0][1:]))]\n",
        "      print(reprojectionErrors)\n",
        "    elif 'ReprojectedPoints' in line:\n",
        "      part = line.split(':')[1].split(\" \")[1].split(\"x\")\n",
        "      reprojectedPoints = [[ [0.0 for col in range(int(part[2]))] for col in range(int(part[1]))] for row in range(int(part[0][1:]))]\n",
        "      print(reprojectedPoints)\n",
        "    elif 'NumPatterns' in line:\n",
        "      numPatterns = int(line.split(':')[1])\n",
        "      print(numPatterns)\n",
        "    elif 'WorldPoints' in line:\n",
        "      part = line.split(':')[1].split(\" \")[1].split(\"x\")\n",
        "      worldPoints = [[0.0]*int(part[1])]*int(part[0][1:])\n",
        "      print(worldPoints)\n",
        "    elif 'WorldUnits' in line:\n",
        "      worldUnits = line.split(':')[1].replace(\"'\",\" \").strip()\n",
        "      print(worldUnits)\n",
        "    elif 'EstimateSkew' in line:\n",
        "      estimateSkew = int(line.split(':')[1])\n",
        "      print(estimateSkew)\n",
        "    elif 'NumRadialDistortionCoefficients' in line:\n",
        "      numRadialDistortionCoefficients = int(line.split(':')[1])\n",
        "      print(numRadialDistortionCoefficients)\n",
        "    elif 'EstimateTangentialDistortion' in line:\n",
        "      estimateTangentialDistortion = int(line.split(':')[1])\n",
        "      print(estimateTangentialDistortion)"
      ],
      "metadata": {
        "id": "sNXSObDOSwnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Intrinsic Matrix değerlerinin verlmesi\n"
      ],
      "metadata": {
        "id": "RK5EWJ9gS2p4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intrinsicMatrix[0][0] = focalLength[0]\n",
        "intrinsicMatrix[1][1] = focalLength[1]\n",
        "intrinsicMatrix[0][2] = principalPoint[0]\n",
        "intrinsicMatrix[1][2] = principalPoint[1]\n",
        "intrinsicMatrix[2][2] = 1\n",
        "intrinsicMatrix"
      ],
      "metadata": {
        "id": "-WhPZvV5SxJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Görüntülerin Ön İşlemesi (Gri Tonlama)"
      ],
      "metadata": {
        "id": "nUJznoB8S1Yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, img in enumerate(images):\n",
        "    # Görüntüyü gri tona dönüştür\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # gray_img = cv2.normalize(gray_img, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
        "    if(i == 1):\n",
        "      cv2_imshow(gray_img)\n",
        "    # Gri tona dönüştürülmüş görüntüyü aynı indeksteki görüntü ile güncelle\n",
        "    images[i] = gray_img"
      ],
      "metadata": {
        "id": "Ug4xmIm9S2Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SIFT ile Keypoint Detection"
      ],
      "metadata": {
        "id": "ABFOJrjaS90Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "previous_frame = images[0]\n",
        "current_frame = images[1]\n",
        "# SIFT kullanarak anahtar noktalarını ve tanımlayıcıları bulma\n",
        "sift = cv2.SIFT_create()\n",
        "\n",
        "# Birinci ve ikinci görüntüdeki anahtar noktalarını ve tanımlayıcıları bulun\n",
        "keypoints1, descriptors1 = sift.detectAndCompute(previous_frame, None)\n",
        "keypoints2, descriptors2 = sift.detectAndCompute(current_frame, None)\n",
        "\n",
        "# BFMatcher kullanarak tanımlayıcıları eşleştirin\n",
        "bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
        "matches = bf.match(descriptors1, descriptors2)\n",
        "\n",
        "# Eşleşmeleri sıralayın\n",
        "matches = sorted(matches, key=lambda x: x.distance)\n",
        "\n",
        "# Eşleşen noktaları ayıklayın\n",
        "points1 = np.array([keypoints1[m.queryIdx].pt for m in matches])\n",
        "points2 = np.array([keypoints2[m.trainIdx].pt for m in matches])"
      ],
      "metadata": {
        "id": "5svuZarBS-vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_world_coordinates(points, K):\n",
        "    points_h = np.hstack((points, np.ones((points.shape[0], 1))))\n",
        "    world_points = np.linalg.inv(K).dot(points_h.T).T\n",
        "    return world_points[:, :2]  # X ve Y koordinatlarını alın\n",
        "\n",
        "world_points1 = to_world_coordinates(points1, intrinsicMatrix)\n",
        "world_points2 = to_world_coordinates(points2, intrinsicMatrix)\n",
        "\n",
        "# Hareket vektörlerini hesaplayın\n",
        "motion_vectors = world_points2 - world_points1"
      ],
      "metadata": {
        "id": "yVd9YSeQTQfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pozisyon tespitinin yapılması"
      ],
      "metadata": {
        "id": "4V9cLrueTStT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import RANSACRegressor, LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import Ridge\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "pixel_size_x = imageSize[0] / focalLength[0]\n",
        "pixel_size_y = imageSize[1] / focalLength[1]\n",
        "\n",
        "# Dönüşüm faktörünü hesaplama (conversion factor)\n",
        "conversion_factor = np.array([1 / pixel_size_x, 1 / pixel_size_y])\n",
        "\n",
        "\n",
        "# RANSAC modelini ayarla\n",
        "degree = 2  # Polinomal derecesi\n",
        "polynomial_regression = make_pipeline(PolynomialFeatures(degree), Ridge())\n",
        "ransac = RANSACRegressor(polynomial_regression,min_samples=0.8, residual_threshold=1.0, max_trials=1500, stop_score=0.99)\n",
        "\n",
        "height, width = flow.shape[:2]\n",
        "X = np.indices((height, width)).reshape(2, -1).T  # Piksel koordinatlarını oluştur\n",
        "y_x = flow[:, :, 0].flatten()  # X yönündeki hareket vektörleri\n",
        "# X yönündeki hareket için RANSAC modelini eğit\n",
        "# ransac.fit(X, y_x)\n",
        "# y_pred_x = ransac.predict(X) * conversion_factor[0]\n",
        "\n",
        "# X yönündeki hareket için RANSAC modelini eğit\n",
        "ransac.fit(world_points1, motion_vectors[:, 0])\n",
        "y_pred_x = ransac.predict(world_points1)*conversion_factor[0]\n",
        "# Y yönündeki hareket için RANSAC modelini eğit\n",
        "X = points1  # Birinci görüntüdeki noktalar\n",
        "y_y = points2[:, 1] - points1[:, 1]  # Y yönündeki hareket\n",
        "ransac = RANSACRegressor(min_samples=0.5, residual_threshold=5.0, max_trials=500, stop_score=0.99)\n",
        "ransac.fit(world_points1, motion_vectors[:, 1])\n",
        "y_pred_y = ransac.predict(world_points1)*conversion_factor[1]\n",
        "\n",
        "# y_pred_y = ransac.predict(X) * conversion_factor[1]\n",
        "\n",
        "# Ortalama hareketi hesapla\n",
        "avg_movement_x = np.mean(y_pred_x)\n",
        "avg_movement_y = np.mean(y_pred_y)\n",
        "\n",
        "print(f'Ortalama hareket X yönünde: {avg_movement_x}')\n",
        "print(f'Ortalama hareket Y yönünde: {avg_movement_y}')"
      ],
      "metadata": {
        "id": "PJwM3lnQTTLj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}